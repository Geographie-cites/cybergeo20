#         if(linkkey %in% names(edges)){edges[[linkkey]]=edges[[linkkey]]+1}else{edges[[linkkey]]=1}
#       }
#     }
#   }
# }
}
}
}
}
gg
com=cluster_louvain(gg)
com
E(gg)$weight_1
E(gg)$weight_2
E(gg)$weight_1
E(gg)$weight_1[which(is.na(E(gg)$weight_1))]=0
E(gg)$weight_1
edges=list()
gg=NULL
for(freqmax in c(10000,15000,20000)){
for(freqmin in c(10,100,200)){
for(kmax in seq(from=1000,to=1500,by=500)){
for(edge_th in seq(from=100,to=200,by=100)){
show(paste0('kmax : ',kmax,' e_th : ',edge_th,' ; freqmin : ',freqmin,' ; freqmax : ',freqmax))
sub = extractSubGraphCommunities(ggiant,kmin,kmax,freqmin,freqmax,edge_th);
if(!is.null(gg)){gg = gg+sub$gg
E(gg)$weight_1[which(is.na(E(gg)$weight_1))]=0;E(gg)$weight_2[which(is.na(E(gg)$weight_2))]=0
E(gg)$weight = E(gg)$weight_1 + E(gg)$weight_2
}else{gg=sub$gg}
# for(i in 1:length(sizes(sub$com))){
#   show(sizes(sub$com)[i])
#   currentcom=V(sub$gg)$name[membership(sub$com)==i]
#   show(currentcom)
#   for(k in 1:length(currentcom)){
#     for(l in 1:length(currentcom)){
#       if(k!=l){
#         k1=currentcom[k];k2=currentcom[l];linkkey=paste0(k1,";",k2)
#         if(linkkey %in% names(edges)){edges[[linkkey]]=edges[[linkkey]]+1}else{edges[[linkkey]]=1}
#       }
#     }
#   }
# }
}
}
}
}
gg
E(gg)$weight
com=cluster_louvain(gg)
com
sizes(com)
edges=list()
gg=NULL
for(freqmax in c(10000,15000,20000)){
for(freqmin in c(100,200)){
for(kmax in seq(from=1000,to=1500,by=500)){
for(edge_th in seq(from=100,to=200,by=100)){
show(paste0('kmax : ',kmax,' e_th : ',edge_th,' ; freqmin : ',freqmin,' ; freqmax : ',freqmax))
sub = extractSubGraphCommunities(ggiant,kmin,kmax,freqmin,freqmax,edge_th);
if(!is.null(gg)){gg = gg+sub$gg
E(gg)$weight_1[which(is.na(E(gg)$weight_1))]=0;E(gg)$weight_2[which(is.na(E(gg)$weight_2))]=0
E(gg)$weight = E(gg)$weight_1 + E(gg)$weight_2
}else{gg=sub$gg}
# for(i in 1:length(sizes(sub$com))){
#   show(sizes(sub$com)[i])
#   currentcom=V(sub$gg)$name[membership(sub$com)==i]
#   show(currentcom)
#   for(k in 1:length(currentcom)){
#     for(l in 1:length(currentcom)){
#       if(k!=l){
#         k1=currentcom[k];k2=currentcom[l];linkkey=paste0(k1,";",k2)
#         if(linkkey %in% names(edges)){edges[[linkkey]]=edges[[linkkey]]+1}else{edges[[linkkey]]=1}
#       }
#     }
#   }
# }
}
}
}
}
com = cluster_louvain(gg)
com
sizes(com)
sum((sizes(com)/length(V(gg)))^2)
edges=list()
gg=NULL
for(freqmax in c(10000,20000)){
for(freqmin in c(100,200)){
for(kmax in seq(from=1000,to=1500,by=500)){
for(edge_th in seq(from=100,to=200,by=50)){
show(paste0('kmax : ',kmax,' e_th : ',edge_th,' ; freqmin : ',freqmin,' ; freqmax : ',freqmax))
sub = extractSubGraphCommunities(ggiant,kmin,kmax,freqmin,freqmax,edge_th);
if(!is.null(gg)){gg = gg+sub$gg
E(gg)$weight_1[which(is.na(E(gg)$weight_1))]=0;E(gg)$weight_2[which(is.na(E(gg)$weight_2))]=0
E(gg)$weight = E(gg)$weight_1 + E(gg)$weight_2
}else{gg=sub$gg}
# for(i in 1:length(sizes(sub$com))){
#   show(sizes(sub$com)[i])
#   currentcom=V(sub$gg)$name[membership(sub$com)==i]
#   show(currentcom)
#   for(k in 1:length(currentcom)){
#     for(l in 1:length(currentcom)){
#       if(k!=l){
#         k1=currentcom[k];k2=currentcom[l];linkkey=paste0(k1,";",k2)
#         if(linkkey %in% names(edges)){edges[[linkkey]]=edges[[linkkey]]+1}else{edges[[linkkey]]=1}
#       }
#     }
#   }
# }
}
}
}
}
gg
list.files('probas/')
load('relevant_full_50000_eth50_nonfiltdico_kmin0_kmax1000_freqmin100_freqmax10000_eth150.RData')
load('probas/relevant_full_50000_eth50_nonfiltdico_kmin0_kmax1000_freqmin100_freqmax10000_eth150.RData')
head(probas)
them_probas = probas
dim(them_probas)
originalities=apply(them_probas,MARGIN = 1,FUN = function(r){if(sum(r)==0){return(0)}else{return(1 - sum(r^2))}})
hist(originalities[originalities>0.6],breaks=50,main="",xlab="originalities")
hist(originalities[originalities>0.6],breaks=100,main="",xlab="originalities")
hist(originalities[originalities>0.6],breaks=100,main="",xlab="originalities")
setwd(paste0(Sys.getenv('CS_HOME'),'/Cybergeo/cybergeo20/HyperNetwork/Data/nw'))
# issue in csv file with semicolon delimiter -> use tabulation instead.
#edges <- read.csv('provnw2_edges.csv',header=FALSE,sep="\t",colClasses=c("character","character"))
#nodes <- read.csv('provnw2_nodes.csv',header=FALSE,sep="\t",colClasses=c("character","character","numeric","numeric"),blank.lines.skip=FALSE)
#colnames(nodes)=c("name","title","year","cyb")
#colnames(edges)=c("from","to")
#vedges = unique(c(edges[,1],edges[,2]))
#vertices = merge(x=data.frame(v=vedges),y=nodes[!duplicated(nodes[,1]),],by.x=1,by.y=1,all.x=FALSE,all.y=TRUE)
#colnames(vertices)=c("name","title","year","cyb")
edges <- read.csv('full_edges.csv',header=FALSE,sep="\t",colClasses=c("character","character"))
#nodes <- read.table('full_nodes.csv',header=FALSE,sep="\t",colClasses=c("character","character","numeric","numeric"),fileEncoding="latin1",encoding="latin1")
colnames(edges)=c("from","to");#colnames(nodes)=c("name","cyb")
s=scan(file='full_nodes.csv',what="character",sep='\n')
nodes = strsplit(s,'\t')
nodes<- data.frame(name=sapply(nodes,function(c){c[1]}),title=sapply(nodes,function(c){c[2]}),year=sapply(nodes,function(c){as.numeric(c[3])}),cyb=sapply(nodes,function(c){as.numeric(c[4])}))
# need to filter ? -> one failed ref
#length(setdiff(nodes$name,vedges))
#setdiff(vedges,nodes$name)
e = as.tbl(edges) %>% filter(from %in% nodes$name & to %in% nodes$name)
# filters 36 edges
vindexes=list()
for(i in 1:nrow(nodes)){vindexes[[as.character(nodes$name[i])]]=i-1}
e = as.tbl(edges) %>% filter(from %in% nodes$name & to %in% nodes$name)
e
gcitation = graph.data.frame(as.data.frame(e),vertices=nodes)
gcitation
cybnodes=V(gcitation)[V(gcitation)$cyb==1]
cybnames=cybnodes$name
length(cybnames)
save(gcitation,cybnames,file=paste0(Sys.getenv('CS_HOME'),'/Cybergeo/cybergeo20/HyperNetwork/Data/nw/citationNetwork.RData'))
names(them_probas)
rownames(them_probas)
load(paste0('processed/',db,'.RData'))
setwd(paste0(Sys.getenv('CS_HOME'),'/Cybergeo/cybergeo20/HyperNetwork/Models/Analysis'))
load(paste0('processed/',db,'.RData'))
keyword_dico=res$keyword_dico
rm(res);gc()
cybindexes = c();cybresnames = c();iscyb=rep(FALSE,length(originalities))
for(cyb in cybnames){
indexes = which(names(keyword_dico)==cyb);
if(length(indexes)>0){
cybindexes=append(cybindexes,indexes[1]);
cybresnames=append(cybresnames,cyb)
iscyb[indexes[1]]=TRUE
}
}
cybindexes = c();cybresnames = c();iscyb=rep(FALSE,length(originalities))
for(cyb in cybnames){
show(cyb)
indexes = which(names(keyword_dico)==cyb);
if(length(indexes)>0){
cybindexes=append(cybindexes,indexes[1]);
cybresnames=append(cybresnames,cyb)
iscyb[indexes[1]]=TRUE
}
}
dat=data.frame(orig=originalities,cyb=iscyb)
sdat=as.tbl(dat)%>%group_by(cyb)%>%summarise(mean=mean(orig))
library(ggplot2)
g=ggplot(dat, aes(x=orig, fill=cyb))
g+ geom_density(alpha=.3)+geom_vline(data=sdat, aes(xintercept=mean,  colour=cyb),linetype="dashed", size=1)
Nb = 10000
nulljournalorigs=c()
for(i in 1:Nb){
probas = them_probas[sample.int(nrow(them_probas), size = length(cybindexes), replace = FALSE),]
cumprobas = colSums(probas)/length(which(rowSums(probas)>0))
nulljournalorigs=append(nulljournalorigs,1 - sum(cumprobas^2))
}
load('probas/relevant_full_50000_eth50_nonfiltdico_kmin0_kmax1000_freqmin100_freqmax10000_eth240.RData')
them_probas = probas
originalities=apply(them_probas,MARGIN = 1,FUN = function(r){if(sum(r)==0){return(0)}else{return(1 - sum(r^2))}})
length(which(rowSums(them_probas)==0))
length(which(rowSums(them_probas)==0))/nrow(them_probas)
length(which(rowSums(them_probas[iscyb])==0))/nrow(them_probas[iscyb])
length(which(rowSums(them_probas[iscyb,])==0))/nrow(them_probas[iscyb,])
kmin = 0
kmax = 1000
edge_th =240
freqmin=100
freqmax=10000
sub = extractSubGraphCommunities(ggiant,kmin,kmax,freqmin,freqmax,edge_th);com=sub$com;gg=sub$gg
summarySubGraphCommunities(sub)
edge_th =150
freqmin=100
freqmax=10000
sub = extractSubGraphCommunities(ggiant,kmin,kmax,freqmin,freqmax,edge_th);com=sub$com;gg=sub$gg
summarySubGraphCommunities(sub)
communities(sub$com)
edge_th =100
freqmin=100
freqmax=10000
sub = extractSubGraphCommunities(ggiant,kmin,kmax,freqmin,freqmax,edge_th);com=sub$com;gg=sub$gg
summarySubGraphCommunities(sub)
communities(sub$com)
kmin = 0
kmax = 1000
edge_th =150
freqmin=50
freqmax=5000
sub = extractSubGraphCommunities(ggiant,kmin,kmax,freqmin,freqmax,edge_th);com=sub$com;gg=sub$gg
summarySubGraphCommunities(sub)
communities(com)
g = filterGraph(g,'data/filter.csv')
g
load(paste0('processed/',db,'.RData'))
g=res$g;
keyword_dico=res$keyword_dico
rm(res);gc()
g = filterGraph(g,'data/filter.csv')
g = filterGraph(g,'data/french.csv')
kmin = 0
kmax = 1000
edge_th =150
freqmin=50
freqmax=5000
sub = extractSubGraphCommunities(ggiant,kmin,kmax,freqmin,freqmax,edge_th);com=sub$com;gg=sub$gg
summarySubGraphCommunities(sub)
communities(com)
com=cluster_fast_greedy(gg)
com=cluster_walktrap(gg)
com
sizs(com)
sizes(com)
com=cluster_walktrap(gg,steps = 8)
sizes(com)
com=cluster_walktrap(gg,steps = 15)
sizes(com)
com=cluster_walktrap(gg,steps = 20)
sizes(com)
com=cluster_walktrap(gg,steps = 30)
sizes(com)
com=cluster_walktrap(gg,steps = 100)
sizes(com)
com=cluster_walktrap(gg,steps = 200)
sizes(com)
com=cluster_walktrap(gg,steps = 150)
sizes(com)
kmin = 0
kmax = 1200
edge_th =100
freqmin=50
freqmax=10000
sub = extractSubGraphCommunities(ggiant,kmin,kmax,freqmin,freqmax,edge_th);com=sub$com;gg=sub$gg
summarySubGraphCommunities(sub)
kmax = 1000
edge_th =100
freqmin=50
freqmax=10000
sub = extractSubGraphCommunities(ggiant,kmin,kmax,freqmin,freqmax,edge_th);com=sub$com;gg=sub$gg
summarySubGraphCommunities(sub)
as_data_frame(gg)
summarySubGraphCommunities(sub)
kmin = 10
kmax = 1000
edge_th =100
freqmin=100
freqmax=10000
sub = extractSubGraphCommunities(ggiant,kmin,kmax,freqmin,freqmax,edge_th);com=sub$com;gg=sub$gg
summarySubGraphCommunities(sub)
freqmax=20000
sub = extractSubGraphCommunities(ggiant,kmin,kmax,freqmin,freqmax,edge_th);com=sub$com;gg=sub$gg
summarySubGraphCommunities(sub)
clust = clusters(g);cmax = which(clust$csize==max(clust$csize))
ggiant = induced.subgraph(g,which(clust$membership==cmax))
sub = extractSubGraphCommunities(ggiant,kmin,kmax,freqmin,freqmax,edge_th);com=sub$com;gg=sub$gg
summarySubGraphCommunities(sub)
kmax = 1400
edge_th =100
freqmin=100
freqmax=10000
sub = extractSubGraphCommunities(ggiant,kmin,kmax,freqmin,freqmax,edge_th);com=sub$com;gg=sub$gg
summarySubGraphCommunities(sub)
edge_th =150
kmax = 1000
edge_th =150
freqmin=100
freqmax=10000
sub = extractSubGraphCommunities(ggiant,kmin,kmax,freqmin,freqmax,edge_th);com=sub$com;gg=sub$gg
summarySubGraphCommunities(sub)
load('probas/relevant_full_50000_eth50_nonfiltdico_kmin0_kmax1000_freqmin100_freqmax10000_eth150.RData')
them_probas = probas
communities(com)
length(communities(com))
thematics = communities(com)
thematics
names(thematics) = c("climate",NULL,"socio-economic",NULL,"agriculture","commerce",NULL,NULL,"health",NULL,NULL,
"biology","communication/politics","spatial analysis",NULL,"GIS","biogeography","physical geography"
)
thematics
names(thematics) = c("climate","NA","socio-economic","NA","agriculture","commerce","NA","NA","health","NA","NA",
"biology","communication/politics","spatial analysis","NA","GIS","biogeography","physical geography"
)
names(thematics) = c("climate","NA","socio-economic","NA","agriculture","commerce","NA","NA","health","NA","NA",
"biology","communication/politics","spatial analysis","NA","GIS","biogeography","physical geography"
)
thematics
length(thematics)
kws
thematics[[2]]
names(thematics)
kws=data.frame()
for(i in 1:length(thematics)){
for(kw in thematics[[i]]){
kws=rbind(kws,c(kw,names(thematics)[i]))
}
}
warnings()
kws
names(thematics)[i]
kw
show(c(kw,names(thematics)[i]))
kws=data.frame()
for(i in 1:length(thematics)){
for(kw in thematics[[i]]){
show(c(kw,names(thematics)[i]))
kws=rbind(kws,c(kw,names(thematics)[i]))
}
}
kws=c()
for(i in 1:length(thematics)){
for(kw in thematics[[i]]){
show(c(kw,names(thematics)[i]))
kws=append(kws,c(kw,names(thematics)[i]))
}
}
kws=c()
for(i in 1:length(thematics)){
if(!is.na(names(thematics)[i])){
for(kw in thematics[[i]]){
show(c(kw,names(thematics)[i]))
kws=append(kws,c(kw,names(thematics)[i]))
}
}
}
load('probas/relevant_full_50000_eth50_nonfiltdico_kmin0_kmax1000_freqmin100_freqmax10000_eth150.RData')
them_probas = probas
names(thematics)=="NA"
export_probas = them_probas[,names(thematics)=="NA"]
names(them_probas)
dim(export_probas)
db
export_probas = them_probas[,names(thematics)!="NA"]
dim(export_probas)
colnames(export_probas) = names(thematics)[names(thematics)!="NA"]
names(thematics)[names(thematics)!="NA"]
head(export_probas)
names(thematics)!="NA"
dim(them_probas)
export_probas = them_probas[,names(thematics)!="NA"]
colnames(export_probas) = names(thematics)[names(thematics)!="NA"]
length(names(thematics))
load(paste0('probas/',dbparams,'.RData'))
dbparams = 'relevant_full_50000_eth50_nonfiltdico_kmin0_kmax1000_freqmin100_freqmax10000_eth150'
load(paste0('probas/',dbparams,'.RData'))
sub$com
com
communities(sub$com)
communities(sub$com)
thematics = communities(sub$com)
names(thematics) = c("NA","NA","GIS","NA","socio-economic","NA","agriculture",
"NA","health","NA","communication/politics","biology","spatial analysis",
"NA","neuroscience","biogeography","NA","climate","commerce","physical geography"
)
kws=c()
for(i in 1:length(thematics)){
if(!is.na(names(thematics)[i])){
for(kw in thematics[[i]]){
show(c(kw,names(thematics)[i]))
kws=append(kws,c(kw,names(thematics)[i]))
}
}
}
# load them probas
#  -> precomputed in semthem_probas
# select existing thematics
export_probas = them_probas[,names(thematics)!="NA"]
colnames(export_probas) = names(thematics)[names(thematics)!="NA"]
head(export_probas)
list.files('export/')
iscyb
names(keyword_dico)
cybergeo
cybergeo <- read.csv(paste0(Sys.getenv('CS_HOME'),'/Cybergeo/cybergeo20/Data/raw/cybergeo.csv'))
as.tbl(cybergeo)
cybergeo <- read.csv(paste0(Sys.getenv('CS_HOME'),'/Cybergeo/cybergeo20/Data/raw/cybergeo.csv'),colClasses = c('integer',rep('character',25)))
as.tbl(cybergeo)
names(keyword_dico)
export_probas$id = names(keyword_dico)
head(export_probas)
export_probas = them_probas[,names(thematics)!="NA"]
colnames(export_probas) = names(thematics)[names(thematics)!="NA"]
# n
names(keyword_dico)
dim(export_probas)
export_probas[,13] = names(keyword_dico)
export_probas = cbind(export_probas,names(keyword_dico))
head(export_probas)
colnames(export_probas)[13]="ID"
as.tbl(cybergeo)
res = as.tbl(export_probas)%>% left_join(as.tbl(cybergeo),by=c("ID","SCHID"))
as.tbl(export_probas)
export_probas = them_probas[,names(thematics)!="NA"]
colnames(export_probas) = names(thematics)[names(thematics)!="NA"]
export_probas = cbind(data.frame(export_probas),names(keyword_dico))
colnames(export_probas)[13]="ID"
res = as.tbl(export_probas)%>% left_join(as.tbl(cybergeo),by=c("ID","SCHID"))
as.tbl(export_probas)
as.tbl(cybergeo)
export_probas = them_probas[,names(thematics)!="NA"]
colnames(export_probas) = names(thematics)[names(thematics)!="NA"]
export_probas = cbind(data.frame(export_probas),as.character(names(keyword_dico)))
colnames(export_probas)[13]="ID"
res = as.tbl(export_probas)%>% left_join(as.tbl(cybergeo),by=c("ID","SCHID"))
res = as.tbl(export_probas)%>% right_join(as.tbl(cybergeo),by=c("ID","SCHID"))
res = as.tbl(export_probas)%>% join(as.tbl(cybergeo),by=c("ID","SCHID"))
res = left_join(as.tbl(export_probas),as.tbl(cybergeo),by=c("ID","SCHID"))
as.tbl(export_probas)
as.tbl(export_probas)$ID
cybid
cybindexes = c();cybresnames = c();iscyb=rep(FALSE,length(originalities));cybid = rep(0,length(originalities))
for(cyb in cybnames){
show(cyb)
indexes = which(names(keyword_dico)==cyb);
id=cybergeo$id[cybergeo$id==cyb]
if(length(indexes)>0){
cybindexes=append(cybindexes,indexes[1]);
cybresnames=append(cybresnames,cyb)
iscyb[indexes[1]]=TRUE
cybid[indexes[1]]=id[1]
}
}
cybid
cyb
cybergeo$id
cybindexes = c();cybresnames = c();iscyb=rep(FALSE,length(originalities));cybid = rep(0,length(originalities))
for(cyb in cybnames){
show(cyb)
indexes = which(names(keyword_dico)==cyb);
id=cybergeo$id[cybergeo$SCHID==cyb]
if(length(indexes)>0){
cybindexes=append(cybindexes,indexes[1]);
cybresnames=append(cybresnames,cyb)
iscyb[indexes[1]]=TRUE
cybid[indexes[1]]=id[1]
}
}
cybid
export_probas = them_probas[,names(thematics)!="NA"]
colnames(export_probas) = names(thematics)[names(thematics)!="NA"]
export_probas = cbind(cybid,data.frame(export_probas))
export_probas
head(export_probas)
names(export_probas)[1] = "CYBERGEOID"
export_probas
mkdir
dir.create(paste0('export/',dbparams))
dir.create(paste0('export/',dbparams))
dir.create(exdir)
exdir=paste0('export/',dbparams)
dir.create(exdir)
write.csv(export_probas,col.names = TRUE,row.names = FALSE,file = paste0(exdir,'/docprobas.csv'))
write.table(export_probas,col.names = TRUE,row.names = FALSE,file = paste0(exdir,'/docprobas.csv'),sep=",")
write.table(kws,col.names = FALSE,row.names = FALSE,file = paste0(exdir,'/thematics.csv'),sep=",")
thematics
kws
kws=c()
for(i in 1:length(thematics)){
if(names(thematics)[i]!="NA"){
for(kw in thematics[[i]]){
show(c(kw,names(thematics)[i]))
kws=append(kws,c(kw,names(thematics)[i]))
}
}
}
kws=c()
for(i in 1:length(thematics)){
if(names(thematics)[i]!="NA"){
for(kw in thematics[[i]]){
show(c(kw,names(thematics)[i]))
kws=append(kws,c(kw,names(thematics)[i]))
}
}
}
data.frame(matrix(kws,ncol=2,byrow=TRUE))
write.table(data.frame(matrix(kws,ncol=2,byrow=TRUE)),col.names = FALSE,row.names = FALSE,file = paste0(exdir,'/thematics.csv'),sep=",")
thematics
colSums(export_probas)
which(is.na(export_probas[,1]))
