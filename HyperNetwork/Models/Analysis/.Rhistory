impactFactor=mean(cyb$Degré.Entrant)
contrQuantile = sapply(quantiles,function(q){mean(cyb$Degré.Entrant[cyb$Degré.Entrant<=quantile(cyb$Degré.Entrant,q)])/impactFactor})
contrQuantile
plot(quantiles,contrQuantile,type="l")
x=rnorm(100)
x
y=rnorm(100)
plot(x,y,axis=FALSE)
plot(x,y,axes=FALSE)
axis(1,pos=0,5)
axis(1,pos=0)
axis(0,pos=0)
axis(2,pos=0)
df
data
d
d <- function(w){
years = c(1,8,17)
dispo = c(27,5 + w * 10,3+w)
return(data.frame(x=years,y=dispo,xl=log(years),yl=log(dispo)))
}
d(0.5)
weights = (1:100)/100
weights
lm(x~y,d(0.5))
slotnames(lm(x~y,d(0.5)))
slotNames(lm(x~y,d(0.5)))
names(lm(x~y,d(0.5)))
names(summary(lm(x~y,d(0.5)))
)
help(append)
weights = (1:100)/100
rlin = c()
rloglin = c()
for(w in weights){
rlin = append(rlin,summary(lm(y~x,d(w)))$adj.r.squared)
rloglin = append(rloglin,summary(lm(yl~xl,d(w)))$adj.r.squared)
}
rlin
rloglin
plot(weights,rlin)
plot(weights,rloglin)
setwd(paste0(Sys.getenv('CS_HOME'),'/PatentsMining'))
overlap <- read.table('Models//Techno//TechnoClasses//res//overlap.csv',sep=";")
links = 0
for(i in 1:nrow(overlap)){
show(i)
links = links + (overlap[i,i]^2)
if(i<nrow(overlap)){
for(j in (i+1):ncol(overlap)){
overlap[j,j] = overlap[j,j] - overlap[i,j]
}
}
}
setwd(paste0(Sys.getenv('CS_HOME'),'/PatentsMining'))
Sys.getenv('CS_HOME')
pr <- prcomp(cormat[1,8:17])
setwd(paste0(Sys.getenv('CN_HOME'),'/Results/Synthetic/Network'))
setwd(paste0(Sys.getenv('CN_HOME'),'/Results/Synthetic/Network'))
getwd()
install.packages('cartography')
install.packages('cartography',source=T)
help(install.packages)
install.packages('cartography',type='source')
library(cartography)
help(cartography)
citation(package="cartography")
resdir='20160106_LHSDensityNW/data/'
cartography: vignette(topic = "cartography")
cartography:vignette(topic = "cartography")
vignette(topic = "cartography")
data("nuts2006")
EuropeStamen <- getTiles(spdf = nuts0.spdf, type = "stamen-watercolor")
install.packages('OpenStreetMap')
EuropeStamen <- getTiles(spdf = nuts0.spdf, type = "stamen-watercolor")
tilesLayer(EuropeStamen)
plot(nuts0.spdf, add=TRUE)
mtext(text = "Map tiles by Stamen Design, under CC BY 3.0. Data by OpenStreetMap, under CC BY SA.",
side = 1, adj = 0, cex = 0.7, font = 3)
install.packages('shiny')
shiny::runApp('~/Documents/ComplexSystems/Misc/Anna/063-superzip-example')
library(maps)
library(mapdata)
library(rworldmap)
setwd(paste0(Sys.getenv('CS_HOME'),'/Cybergeo/cybergeo20/HyperNetwork/Models/Analysis'))
library(dplyr)
library(igraph)
library(RSQLite)
source('networkConstruction.R')
## sqlite data
db = dbConnect(SQLite(),"../Semantic/bootstrap/run_kw1000_csize5000_b20/bootstrap.sqlite3")
relevant = dbReadTable(db,'relevant')
dico = dbReadTable(db,'dico')
nw=exportNetwork(list(relevant=relevant,dico=dico),
kwthreshold=1500,linkthreshold=5,
connex=FALSE,export=FALSE,exportPrefix="graphs/all/all",
filterFile="graphs/all/filter.csv"
)
g=nw$g;keyword_dico=nw$keyword_dico
clust = clusters(g);cmax = which(clust$csize==max(clust$csize))
ggiant = induced.subgraph(g,which(clust$membership==cmax))
kmin = 5
kmin = 4
kmax = 900
edge_th = 50
d=degree(ggiant)
gg=induced_subgraph(ggiant,which(d>kmin&d<kmax))
gg=subgraph.edges(gg,which(E(gg)$weight>edge_th))
com = cluster_louvain(gg)
com
com$names
com$algorithm
help(communities)
gg
kmin = 5
kmax = 900
edge_th = 50
d=degree(ggiant)
gg=induced_subgraph(ggiant,which(d>kmin&d<kmax))
gg=subgraph.edges(gg,which(E(gg)$weight>edge_th))
gg
kmin = 5
kmax = 950
edge_th = 50
d=degree(ggiant)
gg=induced_subgraph(ggiant,which(d>kmin&d<kmax))
gg=subgraph.edges(gg,which(E(gg)$weight>edge_th))
gg
com = cluster_louvain(gg)
com
kmin = 5
kmax = 900
edge_th = 50
d=degree(ggiant)
gg=induced_subgraph(ggiant,which(d>kmin&d<kmax))
gg=subgraph.edges(gg,which(E(gg)$weight>edge_th))
com = cluster_louvain(gg)
com
write.graph(gg,file = 'graphs/filt_kmin5_kmax900_edge50.gml',format = "gml")
kmin = 5
kmax = 750
edge_th = 0
d=degree(ggiant)
gg=induced_subgraph(ggiant,which(d>kmin&d<kmax))
gg=subgraph.edges(gg,which(E(gg)$weight>edge_th))
write.graph(gg,file = paste0('graphs/filt_kmin',kmin,'_kmax',kmax,'_edge',edge_th,'.gml',format = "gml")
)
write.graph(gg,file = paste0('graphs/filt_kmin',kmin,'_kmax',kmax,'_edge',edge_th,'.gml'),format = "gml")
kmin = 5
kmax = 750
edge_th = 10
d=degree(ggiant)
gg=induced_subgraph(ggiant,which(d>kmin&d<kmax))
gg=subgraph.edges(gg,which(E(gg)$weight>edge_th))
com = cluster_louvain(gg)
com
kmin = 5
kmax = 600
edge_th = 10
d=degree(ggiant)
gg=induced_subgraph(ggiant,which(d>kmin&d<kmax))
gg=subgraph.edges(gg,which(E(gg)$weight>edge_th))
com = cluster_louvain(gg)
com
gg
kmin = 5
kmax = 1000
edge_th = 10
d=degree(ggiant)
gg=induced_subgraph(ggiant,which(d>kmin&d<kmax))
gg=subgraph.edges(gg,which(E(gg)$weight>edge_th))
com = cluster_louvain(gg)
com
kmin = 5
kmax = 900
edge_th = 50
d=degree(ggiant)
gg=induced_subgraph(ggiant,which(d>kmin&d<kmax))
gg=subgraph.edges(gg,which(E(gg)$weight>edge_th))
com = cluster_louvain(gg)
thematics = list()
for(i in 1:length(V(gg))){
thematics[[V(g)$name[i]]]=com$membership[i]
}
them_probas = matrix(0,length(names(keyword_dico)),length(unique(com$membership)))
for(i in 1:length(names(keyword_dico))){
if(i%%100==0){show(i)}
kwcount=0
for(kw in keyword_dico[[names(keyword_dico)[i]]]){if(kw %in% names(thematics)){
j=thematics[[kw]]
them_probas[i,j]=them_probas[i,j]+1;kwcount=kwcount+1
}}
if(kwcount>0){them_probas[i,]=them_probas[i,]/kwcount}
}
originalities=apply(them_probas,MARGIN = 1,FUN = function(r){if(sum(r)==0){return(0)}else{return(1 - sum(r^2))}})
hist(originalities,breaks=100)
hist(originalities[originalities>0.6],breaks=100)
hist(originalities[originalities>0.6],breaks=50)
hist(originalities[originalities>0.6],breaks=50,main="",xlab="originalities")
library(igraph)
setwd(paste0(Sys.getenv('CS_HOME'),'/Cybergeo/cybergeo20/HyperNetwork/Data/nw'))
edges <- read.csv('full_edges.csv',header=FALSE,sep="\t",colClasses=c("character","character"))
colnames(edges)=c("from","to");#colnames(nodes)=c("name","cyb")
s=scan(file='full_nodes.csv',what="character",sep='\n')
nodes = strsplit(s,'\t')
nodes<- data.frame(name=sapply(nodes,function(c){c[1]}),title=sapply(nodes,function(c){c[2]}),year=sapply(nodes,function(c){as.numeric(c[3])}),cyb=sapply(nodes,function(c){as.numeric(c[4])}))
cybindexes = c();cybresnames = c()
for(cyb in cybnames){
indexes = which(names(keyword_dico)==cyb);
if(length(indexes)>0){cybindexes=append(cybindexes,indexes[1]);cybresnames=append(cybresnames,cyb)}}
library(dplyr)
e = as.tbl(edges) %>% filter(from %in% nodes$name & to %in% nodes$name)
gcitation = graph.data.frame(as.data.frame(e),vertices=nodes)
cybnodes=V(gcitation)[V(gcitation)$cyb==1]
cybnames=cybnodes$name
citingcyb=c();citedbycyb=c()
for(i in 1:length(cybnodes)){
if(i %% 10==0){show(i)}
citingcyb = append(citingcyb,neighbors(gcitation,v=cybnodes[i],mode="in")$name)
citedbycyb = append(citedbycyb,neighbors(gcitation,v=cybnodes[i],mode="out")$name)
}
i=1
neighbors(gcitation,v=cybnodes[i],mode="in")
neighbors(gcitation,v=cybnodes[i],mode="in")$id
neighbors(gcitation,v=cybnodes[i],mode="in")
vertex_attr_names
vertex_attr_names()
vertex_attr_names(gcitation)
citingcyb=c();citedbycyb=c()
for(i in 1:length(cybnodes)){
if(i %% 10==0){show(i)}
citingcyb = append(citingcyb,neighbors(gcitation,v=cybnodes[i],mode="in")$name)
citedbycyb = append(citedbycyb,neighbors(gcitation,v=cybnodes[i],mode="out")$name)
}
lapply(keyword_dico,length)
sapply(keyword_dico,length)
sapply(keyword_dico,function(x){length(x)^2})
sum(sapply(keyword_dico,function(x){length(x)^2}))
citingcyb=c();citedbycyb=c()
for(i in 1:length(cybnodes)){
if(i %% 10==0){show(i)}
citingcyb = append(citingcyb,neighbors(gcitation,v=cybnodes[i],mode="in")$name)
citedbycyb = append(citedbycyb,neighbors(gcitation,v=cybnodes[i],mode="out")$name)
}
nw$g
ggiant
kmin = 0
kmax = 900
edge_th = 50
d=degree(ggiant)
gg=induced_subgraph(ggiant,which(d>kmin&d<kmax))
gg=subgraph.edges(gg,which(E(gg)$weight>edge_th))
gg
kmax = 1000
edge_th = 50
kmin = 0
kmax = 1000
edge_th = 0
d=degree(ggiant)
gg=induced_subgraph(ggiant,which(d>kmin&d<kmax))
gg=subgraph.edges(gg,which(E(gg)$weight>edge_th))
gg
com = cluster_louvain(gg)
com
gg
max(degree(ggiant))
kmin = 0
kmax = 1200  # max for common ggiant is 1088
edge_th = 0
d=degree(ggiant)
gg=induced_subgraph(ggiant,which(d>kmin&d<kmax))
gg=subgraph.edges(gg,which(E(gg)$weight>edge_th))
gg
com = cluster_louvain(gg)
com
max(E(gg)$weight)
max(E(ggiant)$weight)
kmin = 0
kmax = 1200  # max for common ggiant is 1088
edge_th = 200
d=degree(ggiant)
gg=induced_subgraph(ggiant,which(d>kmin&d<kmax))
gg=subgraph.edges(gg,which(E(gg)$weight>edge_th))
gg
com = cluster_louvain(gg)
com
kmax = 1000  # max for common ggiant is 1088
edge_th = 200  # 6218
d=degree(ggiant)
gg=induced_subgraph(ggiant,which(d>kmin&d<kmax))
gg=subgraph.edges(gg,which(E(gg)$weight>edge_th))
com = cluster_louvain(gg)
com
help(communities)
sizes(com)
gg
kmin = 0
kmax = 1200  # max for common ggiant is 1088
edge_th = 200  # 6218
d=degree(ggiant)
gg=induced_subgraph(ggiant,which(d>kmin&d<kmax))
gg=subgraph.edges(gg,which(E(gg)$weight>edge_th))
com = cluster_louvain(gg)
com
gg
write.graph(gg,file = paste0('graphs/filt_kmin',kmin,'_kmax',kmax,'_edge',edge_th,'.gml'),format = "gml")
getwd()
setwd(paste0(Sys.getenv('CS_HOME'),'/Cybergeo/cybergeo20/HyperNetwork/Models/Analysis'))
write.graph(gg,file = paste0('graphs/filt_kmin',kmin,'_kmax',kmax,'_edge',edge_th,'.gml'),format = "gml")
kmin = 0
kmax = 1000  # max for common ggiant is 1088
edge_th = 200  # 6218
d=degree(ggiant)
gg=induced_subgraph(ggiant,which(d>kmin&d<kmax))
gg=subgraph.edges(gg,which(E(gg)$weight>edge_th))
gg
kmin = 0
kmax = 1050  # max for common ggiant is 1088
edge_th = 200  # 6218
d=degree(ggiant)
gg=induced_subgraph(ggiant,which(d>kmin&d<kmax))
gg=subgraph.edges(gg,which(E(gg)$weight>edge_th))
gg
com = cluster_louvain(gg)
com
write.graph(gg,file = paste0('graphs/filt_kmin',kmin,'_kmax',kmax,'_edge',edge_th,'.gml'),format = "gml")
words<-read.csv('graphs/all/filter.csv')
words
for(w in words){show(w)}
words<-read.csv('graphs/all/filter.csv',stringsAsFactors=FALSE)
for(w in words){show(w)}
filterGraph<-function(graph,file){
words<-read.csv('graphs/all/filter.csv',stringsAsFactors=FALSE)
g=graph
for(w in words){
#show(w)
g=induced_subgraph(g,which(V(g)$names!=w))
}
return(graph)
}
filterGraph(g,'graphs/all/filter.csv')
filterGraph<-function(graph,file){
words<-read.csv('graphs/all/filter.csv',stringsAsFactors=FALSE)
g=graph
for(w in words){
show(w)
g=induced_subgraph(g,which(V(g)$names!=w))
}
return(g)
}
filterGraph(g,'graphs/all/filter.csv')
V(g)$name
filterGraph<-function(graph,file){
words<-read.csv('graphs/all/filter.csv',stringsAsFactors=FALSE)
g=graph
for(w in words){
show(w)
g=induced_subgraph(g,which(V(g)$name!=w))
}
return(g)
}
filterGraph(g,'graphs/all/filter.csv')
V(g)$name
V(g)$name != "paper"
which(V(g)$name != "paper")
length(which(V(g)$name != "paper"))
filterGraph<-function(graph,file){
words<-read.csv('graphs/all/filter.csv',stringsAsFactors=FALSE)
g=graph
for(w in words){
show(w)
g=induced.subgraph(g,which(V(g)$name!=w))
show(length(V(g)))
}
return(g)
}
filterGraph(g,'graphs/all/filter.csv')
which(V(g)$name=="ltd. all right")
length(which(V(g)$name!="ltd. all right"))
filterGraph<-function(graph,file){
words<-read.csv('graphs/all/filter.csv',stringsAsFactors=FALSE)
g=graph
for(w in words){
show(w)
g=induced.subgraph(g,which(V(g)$name!=w))
show(length(V(g)))
}
return(g)
}
filterGraph(g,'graphs/all/filter.csv')
# filter nodes : grep -v -f file for nodes names
filterGraph<-function(graph,file){
words<-read.csv('graphs/all/filter.csv',stringsAsFactors=FALSE)
g=graph
for(w in 1:length(words)){
#show(words[w])
g=induced.subgraph(g,which(V(g)$name!=words[w]))
#show(length(V(g)))
}
return(g)
}
filterGraph(g,'graphs/all/filter.csv')
filterGraph<-function(graph,file){
words<-read.csv('graphs/all/filter.csv',stringsAsFactors=FALSE)
g=graph
for(w in 1:length(words)){
show(words[w])
g=induced.subgraph(g,which(V(g)$name!=words[w]))
show(length(V(g)))
}
return(g)
}
filterGraph(g,'graphs/all/filter.csv')
filterGraph<-function(graph,file){
words<-c(read.csv('graphs/all/filter.csv',stringsAsFactors=FALSE,header=FALSE))
g=graph
for(w in 1:length(words)){
show(words[w])
g=induced.subgraph(g,which(V(g)$name!=words[w]))
show(length(V(g)))
}
return(g)
}
filterGraph(g,'graphs/all/filter.csv')
filterGraph<-function(graph,file){
words<-unlist(read.csv('graphs/all/filter.csv',stringsAsFactors=FALSE,header=FALSE))
g=graph
for(w in 1:length(words)){
show(words[w])
g=induced.subgraph(g,which(V(g)$name!=words[w]))
show(length(V(g)))
}
return(g)
}
filterGraph(g,'graphs/all/filter.csv')
filterGraph<-function(graph,file){
words<-unlist(read.csv('graphs/all/filter.csv',stringsAsFactors=FALSE,header=FALSE))
g=graph
for(w in 1:length(words)){
#show(words[w])
g=induced.subgraph(g,which(V(g)$name!=words[w]))
#show(length(V(g)))
}
return(g)
}
filterGraph(g,'graphs/all/filter.csv')
g = filterGraph(g,'graphs/all/filter.csv')
clust = clusters(g);cmax = which(clust$csize==max(clust$csize))
ggiant = induced.subgraph(g,which(clust$membership==cmax))
kmin = 0
kmax = 1050  # max for common ggiant is 1088
edge_th = 200  # 6218
d=degree(ggiant)
gg=induced_subgraph(ggiant,which(d>kmin&d<kmax))
gg=subgraph.edges(gg,which(E(gg)$weight>edge_th))
gg
write.graph(gg,file = paste0('graphs/filt_kmin',kmin,'_kmax',kmax,'_edge',edge_th,'_handFilt','.gml'),format = "gml")
com = cluster_louvain(gg)
com
kmin = 0
kmax = 1200  # max for common ggiant is 1088
edge_th = 200  # 6218
d=degree(ggiant)
gg=induced_subgraph(ggiant,which(d>kmin&d<kmax))
gg=subgraph.edges(gg,which(E(gg)$weight>edge_th))
write.graph(gg,file = paste0('graphs/filt_kmin',kmin,'_kmax',kmax,'_edge',edge_th,'_handFilt','.gml'),format = "gml")
com = cluster_louvain(gg)
com
com
words
g=nw$g;keyword_dico=nw$keyword_dico
g = filterGraph(g,'graphs/all/filter.csv')
clust = clusters(g);cmax = which(clust$csize==max(clust$csize))
ggiant = induced.subgraph(g,which(clust$membership==cmax))
ggiant
kmin = 0
kmax = 1200  # max for common ggiant is 1088
edge_th = 200  # 6218
d=degree(ggiant)
gg=induced_subgraph(ggiant,which(d>kmin&d<kmax))
gg=subgraph.edges(gg,which(E(gg)$weight>edge_th))
write.graph(gg,file = paste0('graphs/filt_kmin',kmin,'_kmax',kmax,'_edge',edge_th,'_handFilt','.gml'),format = "gml")
com = cluster_louvain(gg)
com
kmin = 0
kmax = 1000  # max for common ggiant is 1088
edge_th = 200  # 6218
d=degree(ggiant)
gg=induced_subgraph(ggiant,which(d>kmin&d<kmax))
gg=subgraph.edges(gg,which(E(gg)$weight>edge_th))
com = cluster_louvain(gg)
gg
com
write.graph(gg,file = paste0('graphs/filt_kmin',kmin,'_kmax',kmax,'_edge',edge_th,'_handFilt','.gml'),format = "gml")
sizes(com)
kmin = 0
kmax = 1000  # max for common ggiant is 1088
edge_th = 50  # 6218
d=degree(ggiant)
gg=induced_subgraph(ggiant,which(d>kmin&d<kmax))
gg=subgraph.edges(gg,which(E(gg)$weight>edge_th))
com = cluster_louvain(gg)
com
edge_th = 100  # 6218
d=degree(ggiant)
gg=induced_subgraph(ggiant,which(d>kmin&d<kmax))
gg=subgraph.edges(gg,which(E(gg)$weight>edge_th))
com = cluster_louvain(gg)
com
write.graph(gg,file = paste0('graphs/filt_kmin',kmin,'_kmax',kmax,'_edge',edge_th,'_handFilt','.gml'),format = "gml")
com
save.image("~/Documents/ComplexSystems/CyberGeo/cybergeo20/HyperNetwork/Models/Analysis/20160217.RData")
