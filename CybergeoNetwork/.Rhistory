ncol.graphLA = merge(ncol.graphLA, lookupLA, by.x = "residenceNow", by.y="codeWICID",  all.x=TRUE)
ncol.graphLA$residenceNow = ncol.graphLA$codeSHP
ncol.graphLA$codeSHP = NULL
ncol.graphLA$Label = NULL
ncol.graphLA$WelshLabel = NULL
ncol.graphLA$N = NULL
ncol.graphCities <- merge(ncol.graphLA, lookup_LA_Cities,  by.x="residenceNow", by.y="LA", all.x=TRUE)
colnames(ncol.graphCities)[length(colnames(ncol.graphCities))] = "residenceNowCities"
ncol.graphCities <- merge(ncol.graphCities, lookup_LA_Cities,  by.x="residenceLastYear", by.y="LA", all.x=TRUE)
colnames(ncol.graphCities)[length(colnames(ncol.graphCities))] = "residenceLastYearCities"
df.1=ncol.graphCities[,c("residenceLastYearCities", "residenceNowCities", "n")]
df.2=data.frame(ncol.graphCities[,c("residenceNowCities","residenceLastYearCities")],-ncol.graphCities[,"n"])
colnames(df.2)=colnames(df.1)
df.3=rbind(df.1,df.2)
G=graph.data.frame(df.3,directed=T)
G=simplify(G,remove.loops = T,remove.multiple = T,edge.attr.comb = "sum")
df.result=data.frame(get.edgelist(G),E(G)$n)
netFlows = df.result
colnames(netFlows) = c("o", "d", "netFlow")
netFlows$direction = ifelse(netFlows$netFlow < 0, SS16[col1], SS16[col2])
coordj <-  centresCities
names(coordj) <- c("Destination","Xj","Yj")
NetCitiesflows <- merge(netFlows, coordj,  by.x="o", by.y="Destination", all.x=TRUE)
coordi <-  centresCities
names(coordi) <- c("Origin","Xi","Yi")
NetCitiesflows <- merge(NetCitiesflows, coordi, by.x="d", by.y = "Origin",  all.x=TRUE)
NetCitiesflows$Dij <- round(sqrt((NetCitiesflows$Xi-NetCitiesflows$Xj)**2
+(NetCitiesflows$Yi-NetCitiesflows$Yj)**2)/1000, 1)
head(NetCitiesflows, 4)
fByD = subset(NetCitiesflows, netFlow > 0)
fByD = fByD[complete.cases(fByD),]
cityJobs = CityPoints@data
colnames(cityJobs) = paste0("o", colnames(CityPoints@data))
fByD = data.frame(fByD, cityJobs[match(fByD$o,cityJobs$oID),])
colnames(cityJobs) = paste0("d", colnames(CityPoints@data))
fByD = data.frame(fByD, cityJobs[match(fByD$d,cityJobs$dID),])
fByD$FlowID = paste0(fByD$oNAME, fByD$dNAME)
fByD$flow_as_percent_of_jobs_at_origin = fByD$netFlow / fByD$oJOBS * 100
fByD$London = ifelse(fByD$oNAME == "London", "at origin",
ifelse(fByD$dNAME == "London", "at destination", "other flow"))
head(t)
par(bg = "white", mfrow=c(1,1), mar = c(1,1,1,1))
p = ggplot(fByD, aes(y=flow_as_percent_of_jobs_at_origin, x=Dij, label = FlowID, colour=London))
p + geom_point() + ggtitle(typeOfFlow)  +  scale_x_log10(limits=c(10,1000))  + scale_y_log10() + geom_smooth(method = "lm", color = SS16[7])
ggsave(paste0("Cities/ShareFlowByDistance", typeOfFlow, "_withLondon.png"))
#
# for (n in cities){
#   #n="Dundee"
#   par(bg = "black", mfrow=c(1,1), mar = c(0,0,1,0))
#
#   codeCities = lookup_Cities[lookup_Cities$NAME == n, "ID"]
#   NetCitiesflowsZoom = subset(NetCitiesflows, o == codeCities)
#
#   NetCitiesflowsZoom = NetCitiesflowsZoom[complete.cases(NetCitiesflowsZoom),]
#   totalNetBalance = sum(as.numeric(NetCitiesflowsZoom$netFlow), na.rm=T)
#   totalTurnover = sum(abs(as.numeric(NetCitiesflowsZoom$netFlow)), na.rm=T)
#   balance = ifelse(totalNetBalance > 0, " | Negative Balance for ", " | Positive Balance for ")
#   print(paste0(n, balance, typeOfFlow, " : ", -totalNetBalance))
#
#   NetCitiesflowsZoom_aboveCutoff = subset(NetCitiesflowsZoom, abs(netFlow) > cutoff)
#   tab <- NetCitiesflowsZoom_aboveCutoff
#   tab$Balance = ifelse(tab$netFlow > 0, -1, 1)
#   balanceFlows = sum(as.numeric(tab$Balance), na.rm=T)
#   tab$B = as.factor(ifelse(tab$netFlow > 0, "outflow", "inflow"))
#
#   c = summary(tab$B)
#   r = c["inflow"] / c["outflow"]
#   if (!is.na(r)) {
#     pattern = "turnover"
#   if (r < 0.66) pattern = "centrifugal"
#   if (r >= 1.5) pattern = "centripetal"
#   } else {
#     if (balanceFlows > 0) pattern = "centrifugal"
#     if (balanceFlows > 0) pattern = "centripetal"
#   }
#
#   tab$shareTurnover = as.numeric(abs(tab$netFlow)) / totalTurnover
#   tab$polarised = ifelse(tab$shareTurnover > 0.33, 1, 0)
#   polarised =  sum(as.numeric(tab$polarised), na.rm=T)
#   if (polarised > 0) pattern = "polarised"
#
#   balanceFlowsByCities[balanceFlowsByCities$Code == codeCities,typeOfFlow] = -totalNetBalance
#   patternFlowsByCities[patternFlowsByCities$Code == codeCities,typeOfFlow] = pattern
#   # tab$Ncommuting = abs(tab[,3])
#   # sel=tab
#   # #  sel <- subset(tab, Ncommuting > cutoff)
#   # png(paste0("Cities/",typeOfFlow,"/Net", cutoff, "_", n, "_black.png"), width = 800, height = 800, units = "px")
#   # plot(uk, col="gray20",border="gray50", lwd = 0.1)
#   # plot(CityPoints, col="gray80", cex = 0.7, pch=16, add=T)
#   # arrows(sel$Xi, sel$Yi, sel$Xj, sel$Yj,
#   #        col=adjustcolor(sel$direction, alpha.f = 0.3) ,
#   #        lwd=sizeFactor * sel$Ncommuting,
#   #        length=0.01, code=2, arr.type="triangle", arr.adj = 1)
#   # title(main=paste0(typeOfFlow, " Net Migrations to and from ", n, " | 2011"), col.main="white") #\n Cutoff = over ", cutoff, ""))
#   # dev.off()
# }
}
for (typeOfFlow in flows) {
#typeOfFlow="All"
patternFlowsByCities[,typeOfFlow] = NA
balanceFlowsByCities[,typeOfFlow] = NA
ncol.graph = df
ncol.graph$n = ncol.graph[,typeOfFlow]
ncol.graphLA = merge(ncol.graph, lookupLA, by.x = "residenceLastYear", by.y="codeWICID",  all.x=TRUE)
ncol.graphLA$residenceLastYear = ncol.graphLA$codeSHP
ncol.graphLA$codeSHP = NULL
ncol.graphLA$Label = NULL
ncol.graphLA$WelshLabel = NULL
ncol.graphLA$N = NULL
ncol.graphLA = merge(ncol.graphLA, lookupLA, by.x = "residenceNow", by.y="codeWICID",  all.x=TRUE)
ncol.graphLA$residenceNow = ncol.graphLA$codeSHP
ncol.graphLA$codeSHP = NULL
ncol.graphLA$Label = NULL
ncol.graphLA$WelshLabel = NULL
ncol.graphLA$N = NULL
ncol.graphCities <- merge(ncol.graphLA, lookup_LA_Cities,  by.x="residenceNow", by.y="LA", all.x=TRUE)
colnames(ncol.graphCities)[length(colnames(ncol.graphCities))] = "residenceNowCities"
ncol.graphCities <- merge(ncol.graphCities, lookup_LA_Cities,  by.x="residenceLastYear", by.y="LA", all.x=TRUE)
colnames(ncol.graphCities)[length(colnames(ncol.graphCities))] = "residenceLastYearCities"
df.1=ncol.graphCities[,c("residenceLastYearCities", "residenceNowCities", "n")]
df.2=data.frame(ncol.graphCities[,c("residenceNowCities","residenceLastYearCities")],-ncol.graphCities[,"n"])
colnames(df.2)=colnames(df.1)
df.3=rbind(df.1,df.2)
G=graph.data.frame(df.3,directed=T)
G=simplify(G,remove.loops = T,remove.multiple = T,edge.attr.comb = "sum")
df.result=data.frame(get.edgelist(G),E(G)$n)
netFlows = df.result
colnames(netFlows) = c("o", "d", "netFlow")
netFlows$direction = ifelse(netFlows$netFlow < 0, SS16[col1], SS16[col2])
coordj <-  centresCities
names(coordj) <- c("Destination","Xj","Yj")
NetCitiesflows <- merge(netFlows, coordj,  by.x="o", by.y="Destination", all.x=TRUE)
coordi <-  centresCities
names(coordi) <- c("Origin","Xi","Yi")
NetCitiesflows <- merge(NetCitiesflows, coordi, by.x="d", by.y = "Origin",  all.x=TRUE)
NetCitiesflows$Dij <- round(sqrt((NetCitiesflows$Xi-NetCitiesflows$Xj)**2
+(NetCitiesflows$Yi-NetCitiesflows$Yj)**2)/1000, 1)
head(NetCitiesflows, 4)
fByD = subset(NetCitiesflows, netFlow > 0)
fByD = fByD[complete.cases(fByD),]
cityJobs = CityPoints@data
colnames(cityJobs) = paste0("o", colnames(CityPoints@data))
fByD = data.frame(fByD, cityJobs[match(fByD$o,cityJobs$oID),])
colnames(cityJobs) = paste0("d", colnames(CityPoints@data))
fByD = data.frame(fByD, cityJobs[match(fByD$d,cityJobs$dID),])
fByD$FlowID = paste0(fByD$oNAME, fByD$dNAME)
fByD$flow_as_percent_of_jobs_at_origin = fByD$netFlow / fByD$oJOBS * 100
fByD$London = ifelse(fByD$oNAME == "London", "flow from London",
ifelse(fByD$dNAME == "London", "flow to London", "other flow"))
head(t)
par(bg = "white", mfrow=c(1,1), mar = c(1,1,1,1))
p = ggplot(fByD, aes(y=flow_as_percent_of_jobs_at_origin, x=Dij, label = FlowID, colour=London))
p + geom_point() + ggtitle(typeOfFlow)  +  scale_x_log10(limits=c(10,1000))  + scale_y_log10() + geom_smooth(method = "lm", color = SS16[7]) +
scale_colour_manual(name = "Category of flow",values = c(SS16[1], SS16[4], SS16[10]))
ggsave(paste0("Cities/ShareFlowByDistance", typeOfFlow, "_withLondon.png"))
#
# for (n in cities){
#   #n="Dundee"
#   par(bg = "black", mfrow=c(1,1), mar = c(0,0,1,0))
#
#   codeCities = lookup_Cities[lookup_Cities$NAME == n, "ID"]
#   NetCitiesflowsZoom = subset(NetCitiesflows, o == codeCities)
#
#   NetCitiesflowsZoom = NetCitiesflowsZoom[complete.cases(NetCitiesflowsZoom),]
#   totalNetBalance = sum(as.numeric(NetCitiesflowsZoom$netFlow), na.rm=T)
#   totalTurnover = sum(abs(as.numeric(NetCitiesflowsZoom$netFlow)), na.rm=T)
#   balance = ifelse(totalNetBalance > 0, " | Negative Balance for ", " | Positive Balance for ")
#   print(paste0(n, balance, typeOfFlow, " : ", -totalNetBalance))
#
#   NetCitiesflowsZoom_aboveCutoff = subset(NetCitiesflowsZoom, abs(netFlow) > cutoff)
#   tab <- NetCitiesflowsZoom_aboveCutoff
#   tab$Balance = ifelse(tab$netFlow > 0, -1, 1)
#   balanceFlows = sum(as.numeric(tab$Balance), na.rm=T)
#   tab$B = as.factor(ifelse(tab$netFlow > 0, "outflow", "inflow"))
#
#   c = summary(tab$B)
#   r = c["inflow"] / c["outflow"]
#   if (!is.na(r)) {
#     pattern = "turnover"
#   if (r < 0.66) pattern = "centrifugal"
#   if (r >= 1.5) pattern = "centripetal"
#   } else {
#     if (balanceFlows > 0) pattern = "centrifugal"
#     if (balanceFlows > 0) pattern = "centripetal"
#   }
#
#   tab$shareTurnover = as.numeric(abs(tab$netFlow)) / totalTurnover
#   tab$polarised = ifelse(tab$shareTurnover > 0.33, 1, 0)
#   polarised =  sum(as.numeric(tab$polarised), na.rm=T)
#   if (polarised > 0) pattern = "polarised"
#
#   balanceFlowsByCities[balanceFlowsByCities$Code == codeCities,typeOfFlow] = -totalNetBalance
#   patternFlowsByCities[patternFlowsByCities$Code == codeCities,typeOfFlow] = pattern
#   # tab$Ncommuting = abs(tab[,3])
#   # sel=tab
#   # #  sel <- subset(tab, Ncommuting > cutoff)
#   # png(paste0("Cities/",typeOfFlow,"/Net", cutoff, "_", n, "_black.png"), width = 800, height = 800, units = "px")
#   # plot(uk, col="gray20",border="gray50", lwd = 0.1)
#   # plot(CityPoints, col="gray80", cex = 0.7, pch=16, add=T)
#   # arrows(sel$Xi, sel$Yi, sel$Xj, sel$Yj,
#   #        col=adjustcolor(sel$direction, alpha.f = 0.3) ,
#   #        lwd=sizeFactor * sel$Ncommuting,
#   #        length=0.01, code=2, arr.type="triangle", arr.adj = 1)
#   # title(main=paste0(typeOfFlow, " Net Migrations to and from ", n, " | 2011"), col.main="white") #\n Cutoff = over ", cutoff, ""))
#   # dev.off()
# }
}
for (typeOfFlow in flows) {
#typeOfFlow="All"
patternFlowsByCities[,typeOfFlow] = NA
balanceFlowsByCities[,typeOfFlow] = NA
ncol.graph = df
ncol.graph$n = ncol.graph[,typeOfFlow]
ncol.graphLA = merge(ncol.graph, lookupLA, by.x = "residenceLastYear", by.y="codeWICID",  all.x=TRUE)
ncol.graphLA$residenceLastYear = ncol.graphLA$codeSHP
ncol.graphLA$codeSHP = NULL
ncol.graphLA$Label = NULL
ncol.graphLA$WelshLabel = NULL
ncol.graphLA$N = NULL
ncol.graphLA = merge(ncol.graphLA, lookupLA, by.x = "residenceNow", by.y="codeWICID",  all.x=TRUE)
ncol.graphLA$residenceNow = ncol.graphLA$codeSHP
ncol.graphLA$codeSHP = NULL
ncol.graphLA$Label = NULL
ncol.graphLA$WelshLabel = NULL
ncol.graphLA$N = NULL
ncol.graphCities <- merge(ncol.graphLA, lookup_LA_Cities,  by.x="residenceNow", by.y="LA", all.x=TRUE)
colnames(ncol.graphCities)[length(colnames(ncol.graphCities))] = "residenceNowCities"
ncol.graphCities <- merge(ncol.graphCities, lookup_LA_Cities,  by.x="residenceLastYear", by.y="LA", all.x=TRUE)
colnames(ncol.graphCities)[length(colnames(ncol.graphCities))] = "residenceLastYearCities"
df.1=ncol.graphCities[,c("residenceLastYearCities", "residenceNowCities", "n")]
df.2=data.frame(ncol.graphCities[,c("residenceNowCities","residenceLastYearCities")],-ncol.graphCities[,"n"])
colnames(df.2)=colnames(df.1)
df.3=rbind(df.1,df.2)
G=graph.data.frame(df.3,directed=T)
G=simplify(G,remove.loops = T,remove.multiple = T,edge.attr.comb = "sum")
df.result=data.frame(get.edgelist(G),E(G)$n)
netFlows = df.result
colnames(netFlows) = c("o", "d", "netFlow")
netFlows$direction = ifelse(netFlows$netFlow < 0, SS16[col1], SS16[col2])
coordj <-  centresCities
names(coordj) <- c("Destination","Xj","Yj")
NetCitiesflows <- merge(netFlows, coordj,  by.x="o", by.y="Destination", all.x=TRUE)
coordi <-  centresCities
names(coordi) <- c("Origin","Xi","Yi")
NetCitiesflows <- merge(NetCitiesflows, coordi, by.x="d", by.y = "Origin",  all.x=TRUE)
NetCitiesflows$Dij <- round(sqrt((NetCitiesflows$Xi-NetCitiesflows$Xj)**2
+(NetCitiesflows$Yi-NetCitiesflows$Yj)**2)/1000, 1)
head(NetCitiesflows, 4)
fByD = subset(NetCitiesflows, netFlow > 0)
fByD = fByD[complete.cases(fByD),]
cityJobs = CityPoints@data
colnames(cityJobs) = paste0("o", colnames(CityPoints@data))
fByD = data.frame(fByD, cityJobs[match(fByD$o,cityJobs$oID),])
colnames(cityJobs) = paste0("d", colnames(CityPoints@data))
fByD = data.frame(fByD, cityJobs[match(fByD$d,cityJobs$dID),])
fByD$FlowID = paste0(fByD$oNAME, fByD$dNAME)
fByD$flow_as_percent_of_jobs_at_origin = fByD$netFlow / fByD$oJOBS * 100
fByD$London = ifelse(fByD$oNAME == "London", "flow from London",
ifelse(fByD$dNAME == "London", "flow to London", "other flow"))
head(t)
par(bg = "white", mfrow=c(1,1), mar = c(1,1,1,1))
p = ggplot(fByD, aes(y=flow_as_percent_of_jobs_at_origin, x=Dij, label = FlowID, colour=London))
p + geom_point() + ggtitle(typeOfFlow)  +  scale_x_log10(limits=c(10,1000))  + scale_y_log10() + geom_smooth(method = "lm", color = SS16[7]) +
scale_colour_manual(name = "Category of flow",values = c(SS16[5], SS16[6], SS16[1]))
ggsave(paste0("Cities/ShareFlowByDistance", typeOfFlow, "_withLondon.png"))
#
# for (n in cities){
#   #n="Dundee"
#   par(bg = "black", mfrow=c(1,1), mar = c(0,0,1,0))
#
#   codeCities = lookup_Cities[lookup_Cities$NAME == n, "ID"]
#   NetCitiesflowsZoom = subset(NetCitiesflows, o == codeCities)
#
#   NetCitiesflowsZoom = NetCitiesflowsZoom[complete.cases(NetCitiesflowsZoom),]
#   totalNetBalance = sum(as.numeric(NetCitiesflowsZoom$netFlow), na.rm=T)
#   totalTurnover = sum(abs(as.numeric(NetCitiesflowsZoom$netFlow)), na.rm=T)
#   balance = ifelse(totalNetBalance > 0, " | Negative Balance for ", " | Positive Balance for ")
#   print(paste0(n, balance, typeOfFlow, " : ", -totalNetBalance))
#
#   NetCitiesflowsZoom_aboveCutoff = subset(NetCitiesflowsZoom, abs(netFlow) > cutoff)
#   tab <- NetCitiesflowsZoom_aboveCutoff
#   tab$Balance = ifelse(tab$netFlow > 0, -1, 1)
#   balanceFlows = sum(as.numeric(tab$Balance), na.rm=T)
#   tab$B = as.factor(ifelse(tab$netFlow > 0, "outflow", "inflow"))
#
#   c = summary(tab$B)
#   r = c["inflow"] / c["outflow"]
#   if (!is.na(r)) {
#     pattern = "turnover"
#   if (r < 0.66) pattern = "centrifugal"
#   if (r >= 1.5) pattern = "centripetal"
#   } else {
#     if (balanceFlows > 0) pattern = "centrifugal"
#     if (balanceFlows > 0) pattern = "centripetal"
#   }
#
#   tab$shareTurnover = as.numeric(abs(tab$netFlow)) / totalTurnover
#   tab$polarised = ifelse(tab$shareTurnover > 0.33, 1, 0)
#   polarised =  sum(as.numeric(tab$polarised), na.rm=T)
#   if (polarised > 0) pattern = "polarised"
#
#   balanceFlowsByCities[balanceFlowsByCities$Code == codeCities,typeOfFlow] = -totalNetBalance
#   patternFlowsByCities[patternFlowsByCities$Code == codeCities,typeOfFlow] = pattern
#   # tab$Ncommuting = abs(tab[,3])
#   # sel=tab
#   # #  sel <- subset(tab, Ncommuting > cutoff)
#   # png(paste0("Cities/",typeOfFlow,"/Net", cutoff, "_", n, "_black.png"), width = 800, height = 800, units = "px")
#   # plot(uk, col="gray20",border="gray50", lwd = 0.1)
#   # plot(CityPoints, col="gray80", cex = 0.7, pch=16, add=T)
#   # arrows(sel$Xi, sel$Yi, sel$Xj, sel$Yj,
#   #        col=adjustcolor(sel$direction, alpha.f = 0.3) ,
#   #        lwd=sizeFactor * sel$Ncommuting,
#   #        length=0.01, code=2, arr.type="triangle", arr.adj = 1)
#   # title(main=paste0(typeOfFlow, " Net Migrations to and from ", n, " | 2011"), col.main="white") #\n Cutoff = over ", cutoff, ""))
#   # dev.off()
# }
}
dim(fByD)
62*62
runApp('~/Documents/cybergeo20/Cybergeo20')
load("data/CyberData.RData")
setwd("~/Documents/cybergeo20/Cybergeo20")
load("data/CyberData.RData")
allArticles <- cyberData$ARTICLES
years=2015
years = yearValues$years
articles = allArticles[substr(allArticles$date.1, 1, 4) %in% as.character(years),]
head(articles)
years=2001
articles = allArticles[substr(allArticles$date.1, 1, 4) %in% as.character(years),]
head(articles)
articles
head(articles)
cols = colnames(articles)
cols
cols[substr(cols,1, 2) == "A_"]
colSums(articles[,authoring)
colSums(articles[,authoring])
authoring = cols[substr(cols,1, 2) == "A_"]
colSums(articles[,authoring])
sumsByCountry = colSums(articles[,authoring])
sumsByCountry[sumsByCountry>0]
length(sumsByCountry[sumsByCountry>0])
sort(sumsByCountry)
authoringCountries = sumsByCountry[sumsByCountry>0]
length(authoringCountries)
sort(authoringCountries)
-sort(authoringCountries)
sort(-authoringCountries)
order(authoringCountries)
tail(sort(authoringCountries))
sort(authoringCountries), decrease = T)
sort(authoringCountries), decreasing = T)
sort(authoringCountries, decreasing = T)
names(authoringCountries) = substr(names(authoringCountries), 3, 4)
sort(authoringCountries, decreasing = T)
head(sort(authoringCountries, decreasing = T))
runApp()
runApp()
head(sort(studiedCountries, decreasing = T))
AC = sort(authoringCountries, decreasing = T)
AC
paste0(AC[1:5])
paste0(names(AC[1]), AC[1], names(AC[2]), AC[2]))
paste0(names(AC[1]), AC[1], names(AC[2]), AC[2])
paste(names(AC[1]), AC[1], names(AC[2]), AC[2], sep=" ")
paste(names(AC[1]), "=", AC[1], ",", names(AC[2]), "=", AC[2], sep=" ")
paste0(names(AC[1]), " (", AC[1], "), ", names(AC[2]), " (",  AC[2], ")")
runApp()
load("data/CyberData.RData")
articles = data.frame()
allArticles <- cyberData$ARTICLES
articles = allArticles[substr(allArticles$date.1, 1, 4) %in% as.character(years),]
articles
runApp()
articlesDF = articles
nPapers = dim(articlesDF)[1]
nPapers
years = 1996:2015
articles = allArticles[substr(allArticles$date.1, 1, 4) %in% as.character(years),]
articlesDF = articles
nPapers = dim(articlesDF)[1]
tab[1,1] = "Number of scientific articles"
tab[1,2] = nPapers
tab
tab = data.frame()
tab[1,1] = "Number of scientific articles"
tab[1,2] = nPapers
tab
articlesDF$authorsLists = strsplit(articlesDF$authors, split = ",")
for (i in 1:dim(articlesDF)[1]) {
articlesDF[i,"Nauthors"] = ifelse(is.na(articlesDF[i,"authorsLists"]), 1, length(articlesDF[i,"authorsLists"][[1]]))
}
Nauthors = sum(articlesDF$Nauthors)
Nauthors
tab[2,1] = "Number of authors"
tab[2,2] = Nauthors
cols = colnames(articles)
authoring = cols[substr(cols,1, 2) == "A_"]
sumsAByCountry = colSums(articles[,authoring])
authoringCountries = sumsAByCountry[sumsAByCountry>0]
nAuthoringCountries = length(authoringCountries)
tab[3,1] = "Number of countries authoring"
tab[3,2] = nAuthoringCountries
tab
runApp()
runApp()
load("data/20-themes.RData")
load("data/themesPO.RData")
themesPO
load("/Users/clementinecottineau/Documents/cybergeo20/Cybergeo20/data/themesPO.Rdata")
load("~/Documents/cybergeo20/Cybergeo20/data/themesPO.Rdata")
View(themes.termes)
load("~/Documents/cybergeo20/Cybergeo20/data/themesPO.Rdata")
View(files)
View(document.themes)
View(themes.termes)
load("data/themesPO.RData")
head(themes.termes)
View(themes.termes)
View(document.themes)
head(document.themes)
View(files)
load("data/themesPO.RData")
files[,5:24] = document.themes
head(files)
load("data/themesPO.RData")
files$names = NULL
files$path = NULL
files[,3:22] = document.themes
head(files)
load("data/themesPO.RData")
files$name = NULL
files$path = NULL
files[,3:22] = document.themes
head(files)
20themeDescription = read.csv("data/20themes20words.csv", sep=",", dec=".")
themeDescription = read.csv("data/20themes20words.csv", sep=",", dec=".")
head(themeDescription)
themeDescription = read.csv("data/20themes20words.csv", sep=",", dec=".")
head(themeDescription)
themeDescription = read.csv("data/20themes20words.csv", sep=",", dec=".")
head(themeDescription)
head(files)
head(articles)
articles = allArticles[substr(allArticles$date.1, 1, 4) %in% as.character(years),]
allArticles <- cyberData$ARTICLES
load("data/CyberData.RData")
allArticles <- cyberData$ARTICLES
years = 1996:1999
articles = allArticles[substr(allArticles$date.1, 1, 4) %in% as.character(years),]
articles = merge(articles, files, by.x = , by.y = "id" , all.x = T, all.y = F)
head(articles)
articlesDF = subsetArticles()
articlesDF = articles
cols = colnames(articlesDF)
cols
cols[substr(cols,1, 1) == "V"]
c = length(cols)
cols[c-20 : c]
c20 = length(cols)
c1 = c - 19
cols[c1:c20]
sumsByTheme = colSums(articlesDF[themes])
c20 = length(cols)
c1 = c - 19
themes =  cols[c1:c20]
sumsByTheme = colSums(articlesDF[themes])
sumsByTheme
sumsByTheme = colSums(articlesDF[themes], na.rm = T)
sumsByTheme
names(sumsByTheme) = paste0("T", 1:20)
sumsByTheme
sort(s)
sort(sumsByTheme)
sort(sumsByTheme, decreasing = T)
names(sumsByTheme) = paste0("T_", 1:20)
sort(sumsByTheme, decreasing = T)
sortesThemes = sort(sumsByTheme, decreasing = T)
sortesThemes
sortedThemes = sort(sumsByTheme, decreasing = T)
themeDescription[as.numeric(substr(names(sortedThemes)[1]),]
themeDescription[as.numeric(substr(names(sortedThemes)[1])),]
substr(names(sortedThemes)[1], 3, 3)
themeDescription[as.numeric(substr(names(sortedThemes)[1], 3, 3)),]
runApp()
topTheme = themeDescription[as.numeric(substr(names(sortedThemes)[1], 3, 3)),]
str(topTheme)
topTheme = themeDescription[as.numeric(substr(names(sortedThemes)[1], 3, 3)),2]
str(topTheme)
topTheme
runApp()
topTheme = as.character(topTheme)
topTheme
runApp()
sumsByTheme = colSums(articlesDF[,themes], na.rm = T)
sumsByTheme
runApp()
themes
colSums(articlesDF[,themes], na.rm = T)
paste0("T_", 1:20)
themes =  cols[paste0("T_", 1:20)]
themes
themes =  paste0("T_", 1:20)
colSums(articlesDF[,themes], na.rm = T)
runApp()
head(articlesDF)
sumsCitations = colSums(articlesDF[,c("citedby", "citing")], na.rm = T)
as.numeric(sumsCitations[1])
as.numeric(sumsCitations[1])
as.numeric(sumsCitations[2])
runApp()
